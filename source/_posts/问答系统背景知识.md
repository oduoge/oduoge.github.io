---
title: 问答系统背景知识
date: 2020-11-05 14:50:15
tags:
- 待整理
categories:
- 问答系统
---

# 简介

&emsp;&emsp;[问答系统(Question Answering System, QA)](https://baike.baidu.com/item/%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/9641943)是信息检索系统的一种高级形式。它能用准确、简洁的自然语言回答用户用自然语言提出的问题。其研究兴起的主要原因是人们对快速、准确地获取信息的需求。问答系统是目前人工智能和自然语言处理领域中一个倍受关注并具有广泛发展前景的研究方向。国际上，问答系统的研究方兴未艾，许多大的科研院所和著名公司，都积极参与到该领域的研究,中文问答系统需要在现有的中文信息处理技术基础上，充分研究和利用问答的特性与需求，通过各种方法解决和克服(或暂时回避)以上难点和困难，设计和开发问答系统。
<!-----more ------->
&emsp;&emsp;问答系统外部的行为上来看，其与目前主流资讯检索技术有两点不同：首先是查询方式为完整而口语化的问句，再来则是其回传的为高精准度网页结果或明确的答案字串。  
&emsp;&emsp;以Ask Jeeves为例，使用者不需要思考该使用什么样的问法才能够得到理想的答案，只需要用口语化的方式直接提问如`「请问谁是美国总统？」`即可。而系统在了解使用者问句后，会非常清楚地回答`「奥巴马是美国总统」`。面对这种系统，使用者不需要费心去一一检视搜寻引擎回传的网页，对于资讯检索的效率与资讯的普及都有很大帮助。从系统内部来看，问答系统使用了大量有别于传统资讯检索系统自然语言处理技术，如自然语言剖析（`Natural Language Parsing`）、问题分类（`Question Classification`）、专名辨识（`Named Entity Recognition`）等等。少数系统甚至会使用复杂的逻辑推理机制，来区隔出需要推理机制才能够区隔出来的答案。在系统所使用的资料上，除了传统资讯检索会使用到的资料外（如字典），问答系统还会使用本体论等语义资料，或者利用网页来增加资料的丰富性。  
&emsp;&emsp;问答系统接受的是自然语言问句，为了有效控制研究变因，多会定制可接受的问题类型来限制研究范围。最基本的类型为「仿真陈述问答」（`Factoid Question Answering`），此类系统根据答案语料所述资讯，取出一小段字串作为答案。由于答案的正确与否是根据答案语料的内容来决定，在现实生活中不一定为真，故称为仿真陈述问答。  
&emsp;&emsp;有些系统把问答范围进一步缩小，限定在人、地、组织等明确的专有名词上。若此类系统有能力回答如 **「请列举美国历届总统」** 这种清单型的问句，则称为 **「清单问答」**  `（List Question Answering）`；若能回答定义问题，则称为 **「定义问答」** `（ Definition Question Answering）`；以此类推还能定义出其他类型的问题。除了这些与问句资讯内容有关的类型外，最近评鉴会议引进如「时间限制问题」（Temporally Restricted Questions）与「序列问题」（Series of Questions）等复杂的问题类型。时间限制型的问题会在问句中明确指出答案的时间范围限制，比如说以「民国九十年时的国民党主席是谁」这问句来说，系统必须有根据答案语料结构化资料，或上下文来推论正确答案的能力。序列问题则把问答系统未来的应用定位在互动式的系统上。经过来回多次问答的方式来满足使用者的资讯需求。了解这些问题类型分类，有助于研究范围界定，同时在分析比较上也比较有依据。  
&emsp;&emsp;我们可以从知识领域、答案来源等角度来替问答系统做分类。从知识领域来看，可分为「封闭领域」以及「开放领域」两类系统。封闭领域系统专注于回答特定领域的问题，如医药或特定公司等。由于问题领域受限，系统有比较大的发挥空间，可以导入如专属本体论等知识，或将答案来源全部转换成结构性资料，来有效提升系统的表现。开放领域系统则希望不设限问题的内容范围，天文地理无所不问。系统中所有知识与元件都必须尽量做到与领域不相关，当然难度也相对地提高。  
&emsp;&emsp;若根据答案来源来区分，可分为「知识库问答」、「常问问题问答」、「新闻问答」、「网际网路问答」等系统。知识库是最常见的结构化资料储存媒介，我们在下面对其进行简单介绍。虽然透过操控SQL语言便能够有效率地存取资料，但有些系统试图提供更直觉的自然语言查询介面，希望能进一步降低学习门槛。  
&emsp;&emsp;知识库问答（knowledge base question answering, KB-QA）即给定自然语言问题，通过对问题进行语义理解和解析，进而利用知识库进行查询、推理得出答案。  

# KB-QA 具有以下特点：

1. 答案  
回答的答案是知识库中的实体或实体关系，或者 no-answer（即该问题在 KB 中找不到答案），当然这里答案不一定唯一，比如中国的城市有哪些 。

2. 评价标准  
回召率（Recall），精确率（Precision)），F1-Score。  

&emsp;&emsp;当我们在百度询问 2016 年奥斯卡最佳男主角时，百度会根据知识库进行查询和推理，返回答案，这其实就是 KB-QA 的一个应用。

# 发展历史

&emsp;&emsp;早在1961年，Green就发展了第一个问答系统，用来回答单季美国职棒大联盟相关比赛问题。该系统执行于IBM 7090平台，以今日的观点来看，其硬体资源相当贫乏，但由于问答的范围狭小，系统正确率尚能达到令人满意的地步。受限于当时的技术水平，早期的问答系统大部分是封闭领域系统。著名的项目有上个世纪60年代研制的LUNAR系统，专事回答有关阿波罗登月返回的月球岩石样本的地质分析问题。SHRDLE 是另一个基于人工智能的专家系统，模拟的是机器人在玩具积木世界中的操作，机器人可以回答这个玩具世界的几何状态的问题，并听从语言指令进行合法操作。  
&emsp;&emsp;20世纪70年代和80年代，计算语言学综合理论的发展，导致了文本理解和问答的雄心勃勃的项目的发展。这种系统的一个例子是Unix顾问（UC），由Robert Wilensky在U.C伯克利在20世纪80年代末期开发。该系统回答了与Unix操作系统有关的问题。它拥有一个较全面的手工设计的领域知识库。另一个项目是LILOG，一个文本理解系统，在德国城市的旅游信息领域运作。  
&emsp;&emsp;1999年，搜索业界的第八届年会（TREC-8：Text REtrieval Conference）决定增加一个问答系统的竞赛，美国国防部有名的DARPA项目资助，由美国国家标准局组织实施，这是开放式问答系统的正式诞生。但早期的问答系统研究并不顺利，并且当时的相关算法（如信息抽取）表现也不够先进，一直到2010年后，问答系统才又一次变成了研究热点。  
&emsp;&emsp;2013年，Jonathan Berant等人训练了一个可扩展到Freebase的语义解析器。 他们从问答对中学习，而不是依赖于注释的逻辑形式，因为这对于大规模获取来说特别昂贵。 此设置中的主要挑战是缩小给定问题的大量可能的逻辑谓词。 他们以两种方式解决这个问题：首先，我们使用知识库和大型文本语料库构建从短语到谓词的粗略映射。 其次，他们使用桥接操作基于相邻谓词生成其他谓词。  
&emsp;&emsp;2014年Antoine Bordes, Sumit Chopra, Jason Weston介绍的系统使用了向量建模，该系统学习使用少量人工设计的特征从知识库中回答关于广泛主题的问题。 他们的模型学习单词和知识库成分的低维嵌入; 这些表示用于根据候选答案对自然语言问题进行评分。  
&emsp;&emsp;2015年，Li Dong等人针对当时大多数系统通常依赖于手工制作的功能和规则来进行问题理解和/或答案排名，引入了多列卷积神经网络（MCCNN）来从三个不同方面（即答案路径，答案上下文和答案类型）理解问题并学习它们的分布式表示。他们使用FREEBASE作为知识库，并在WEBQUESTIONS数据集上进行大量实验。实验结果表明，与基线系统相比，他们的方法具有更好或相当的性能。此外，他们开发了一种计算不同列网络中问题词的显着性得分的方法，有助于直观地了解MCCNN的学习内容。  
&emsp;&emsp;同年，来自微软的Scott Wen-tau Yih和Jianfeng Gao等人提出了一种新的语义解析框架，用于使用知识库进行问答。 他们定义了一个类似于知识库子图的查询图，可以直接映射到逻辑表单。 语义解析被简化为查询图生成，被公式化为分阶段搜索问题。他们的方法在早期利用知识库来修剪搜索空间，从而简化语义匹配问题。 通过应用先进的实体链接系统和匹配问题和谓词序列的深度卷积神经网络模型，他们的系统在WebQuestions数据集上实现了52.5％的F1测量。  
&emsp;&emsp;因为自然语言处理中的大多数任务都可以转换为语言输入的问题回答（QA）问题，2017年，Ankit Kumar和Richard Socher等人改进了动态内存网络（DMN），这是一种处理输入序列和问题，形成情景记忆并生成相关答案的神经网络体系结构。 问题触发迭代注意过程，该过程允许模型将其注意力放在输入和先前迭代的结果上。 然后在分层递归序列模型中推导出这些结果以产生答案。 DMN可以端到端地进行培训，并在几种类型的任务和数据集上获得了当时最先进的结果：问答（Facebook的bAbI数据集），情感分析的文本分类（斯坦福情感树库）和序列建模 词性标注（WSJ-PTB）。 对这些不同任务的训练完全依赖于训练有素的单词矢量表示和输入 - 问题 - 答案三元组。  
&emsp;&emsp;2018年，Adams Wei Yu , David Dohan , Minh-Thang Luong认为目前的端到端机器阅读和问答（Q&A）模型主要基于带注意力机制的循环神经网络（RNN）。尽管它们取得了一定程度的成功，但由于 RNN 的序列特性，这些模型的训练速度和推断速度通常较慢。他们提出了一个名为 QANet 的新型问答系统框架，它不再需要循环网络：其编码器仅仅由卷积和自注意力机制构成，卷积可以对局部相互作用建模，而自注意力机制可以对全局相互作用建模。在 SQuAD 数据集上，QANet 模型的训练速度提升到对应的 RNN 模型的 3 到 13 倍、推断速度提升到 4 到 9 倍，并且取得了和循环模型同等的准确率。他们将 QANet 模型和使用神经机器翻译模型回译得到的数据结合了起来。在 SQuAD 数据集上，他们使用增强的数据训练的模型在测试集上获得了 84.6 的 F1 值，这远远优于当时公开的最佳模型 81.8 的 F1 值。  
&emsp;&emsp;同年，随着近年来知识库的快速发展，基于知识库的问答系统（KBQA ）吸引了业界的广泛关注。该类问答系统秉承先编码再比较的设计思路，即先将问题和知识库中的三元组联合编码至统一的向量空间，然后在该向量空间内做问题和候选答案间的相似度计算。该类方法简单有效，可操作性比较强，然而忽视了很多自然语言词面的原始信息。因此，Yingqi Qu, Jie Liu, Liangyi Kang, Qinfeng Shi, Dan Ye提出了一种 Attentive RNN with Similarity Matrix based CNN（AR-SMCNN）模型，利用 RNN 和 CNN 自身的结构特点分层提取有用信息。文中使用 RNN 的序列建模本质来捕获语义级关联，并使用注意机制同时跟踪实体和关系。同时，文中使用基于 CNN 的相似矩阵和双向池化操作建模数据间空间相关性的强度来计算词语字面的匹配程度。此外，文中设计了一种新的实体检测启发式扩展方法，大大降低了噪声的影响。文中的方法在准确性和效率上都超越了 SimpleQuestion 基准测试的当时最好水平。

# 发展分析

## 瓶颈
&emsp;&emsp;自然语言问句的理解是智能问答系统中最核心也是最困难的一个环节， 因为这个环节实际上要解决的问题是如何将自然语言最准确地转化为计算机可以表示和理解的形式。这个不仅是智能问答系统需要解决的问题，也是人工智能领域所需要解决的最核心的难题之一。此外，目前的知识库远远不能满足开发领域智能问答系统对知识资源的需求，更何况现在绝大多数的知识都存在于非结构化的文本数据中。在不同领域的多个知识资源库是存在的，但如何将所有异构的知识源统一起来，形成一个形式统一的知识源满足用户的统一查询需求也是一个问题。

## 未来发展方向
&emsp;&emsp;问答系统的使用是一个对话过程，而需要语义接地，即将自然语言映射到内部的表征，如何定义和使用语义表征是一个核心问题。  
&emsp;&emsp;语言理解的多义性、多样性问题。虽然迄今有很多研究，但仍然没有根本解决。  
&emsp;&emsp;语言和知识，既可以由符号表征，又可以由向量表征（神经表征），各有优缺点，如何将符号处理和深度学习结合是一个重要的问题。  
&emsp;&emsp;问答系统是一个复杂的系统，需要进行层次化和模块化处理，如何构建这样的系统，并使其拥有自动学习功能也是一个大问题。  
&emsp;&emsp;机器学习的数据往往是不够的，这使得端对端训练系统变得困难，在小样本的条件下训练模型是需要解决的重要课题。


`https://www.jiqizhixin.com/graph/technologies/fca61fff-ab9b-4ee2-8716-bbd8e7a44507`


# 系统研究

中文问答系统相对于英文有如下几个方面的难点或不足之处：
- 连写：中文是连续书写，分词是汉语言处理的基础。中文问答系统由于是句子级别的信息检索，要分析句子，首先要分词。
- 形态：汉语缺乏狭义的形态变化，如英文中的主动被动语态，完成时进行时等，形态对于计算机就是标记，有利于计算机的处理。
- 语法：汉语语法灵活，句子各成分之间的关系靠词序、“意合”、虚词，变化较多。
- 语义：一词多义、同音词、同义词、近义词等，以及丰富的表达方式，上下文依赖度高，省略语等都是计算机处理的难点。
- 语法研究：面向计算机处理的中文语法研究不足，如中文问答系统需要的关于中文句型形式化、不同句型之间的转换的研究资料极少。
- 相关资源：缺乏包括语法、语义词典等中文语言学资源和相关生熟语料，国外这方面强得多，如TREC就提供的相当数量的可用于英文问答研究和评测的语料。  
&emsp;&emsp;中文问答系统需要在现有的中文信息处理技术基础上，充分研究和利用问答的特性与需求，通过各种方法解决和克服(或暂时回避)以上难点和困难，设计和开发问答系统。

# 系统应用

&emsp;&emsp;问答系统主要应用于web形式的问答网站，代表作有：百度知道、新浪爱问、天涯问答、雅虎知识堂、果壳、知乎网等这些即问即答网站。





智能问答是个覆盖范围广泛的领域。按照目前主流的方向来划分，其中包括了（暂不考虑FAQ问答）：

1、KBQA；2、IR-based QA；3、Community QA；4、Open-domain QA；5、MRC；（开放域的问答和MRC有共通的部分）

作者：xingluxi
链接：https://www.zhihu.com/question/349499033/answer/902873433
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

1 研究任务：从ACL/EMNLP/NAACL三大顶会的趋势看，就我关注到的内容而言，有两个任务热度很高：1、Multi-hop QA，尤其是在HotpotQA任务上，同类数据集 WikiHop 关注度在今年略有下降，但是ACL2019上的很多工作都启发自基于WikiHop任务的工作；2、FEVER（Fact Extraction and Verification） ，在EMNLP2019上开设了单独的一个Workshop，是个具有实用价值的任务；2（期待看到的）研究方向有以下几点：1、更多类型的任务，更难的数据集，MRC的主要特点是任务导向+数据驱动，任务/数据集推动模型迭代。更多类型的任务指测试机器单一问答能力的任务，比如只测试模型回答因果关系（Event2Mind），还有题主回答评论中提及的MathQA、BoolQA等。更难的数据集测试QA模型的鲁棒性。此外，还有具备可解释性监督信号的数据集以及跨语言QA数据集。2、尝试用 unsupervised learning 或 few-shot learning 的方式训练QA模型。参考：Unsupervised Question Answering by Cloze Translation. ACL,2019.3、生成式QA，如何生成自然语言语句构成的答案，这个方向上，还缺乏针对评价生成答案的指标；4、KBQA 在向融合文本信息的方向上发展，Open-domainQA和MRC在向同时融合结构化知识和文本知识等异构信息的方向上发展。



研究方向

- 非事实类问题  
大多数研究关注于事实类问题，而非事实类问题的研究相对不足，包括数学类的问题、判断类的问题等。  
[EMNLP 2019] NumNet: Machine Reading Comprehension with Numerical Reasoning 数学类问题  
NAACL19 - MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms  
NAACL19 - BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions

- 多跳推理

>作者：Y.Shu
>链接：https://www.zhihu.com/question/349499033/answer/900173774
>来源：知乎
>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

- 多跳（multi-hop）  
在最近的顶会上关注度非常高，目前实现这一机制的方法也比较复杂。  
[EMNLP 2019] What's Missing: A Knowledge Gap Guided Approach for Multi-hop Question Answering  
[EMNLP 2019] Self-Assembling Modular Networks for Interpretable Multi-Hop Reasoning  
[EMNLP 2019] Avoiding Reasoning Shortcuts: Adversarial Evaluation, Training, and Model Development for Multi-Hop QA  
[ACL 2019] Multi-Hop Paragraph Retrieval for Open-Domain Question Answering  
[ACL 2019] Dynamically Fused Graph Network for Multi-hop Reasoning  
[ACL 2019] Explore, Propose, and Assemble: An Interpretable Model for Multi-Hop Reading Comprehension  
[ACL 2019] Multi-hop Reading Comprehension through Question Decomposition and Rescoring  
[ACL 2019] Compositional Questions Do Not Necessitate Multi-hop Reasoning  
[ACL 2019] Answering while Summarizing: Multi-task Learning for Multi-hop QA with Evidence Extraction  
[ACL 2019] Cognitive Graph for Multi-Hop Reading Comprehension at Scale  
[ACL 2019] Understanding Dataset Design Choices for Multi-hop Reasoning  
[NAACL 2019] Repurposing Entailment for Multi-Hop Question Answering Tasks  
[NAACL 2019] BAG: Bi-directional Attention Entity Graph Convolutional Network for Multi-hop Reasoning Question Answering  
[ACL 2019] Exploiting Explicit Paths for Multi-hop Reading Comprehension  
[ACL 2019] Multi-hop reading comprehension across multiple documents by reasoning over heterogeneous graphs
- 多语言/跨语言的问答  
包括英法德等主流语言之间的研究，也包括特定于使用人数较少的语言的研究。  
[EMNLP 2019] Cross-Lingual Machine Reading Comprehension  
[EMNLP 2019] BiPaR: A Bilingual Parallel Dataset for Multilingual and Cross-lingual Reading Comprehension Novels  
[ACL 2019] XQA: A Cross-lingual Open-domain Question Answering Dataset
- 知识库问答和基于文本的问答的结合  
前者通常是限定域的，知识容量有限，结构化信息比较好查询；后者通常是开放域的，信息量很大，但是提取知识比较困难。  
[EMNLP 2019] Language Models as Knowledge Bases? 探索语言模型作为知识来源的可能性  
[ACL 2019] Interpretable Question Answering on Knowledge Bases and Text  
[ACL 2019] Enhancing Pre-Trained Language Representations with Rich Knowledge for Machine Reading Comprehension  
[EMNLP 2019] Incorporating External Knowledge into Machine Reading for Generative Question Answering长文本/多段落MRC 的研究在向多段落/长文本扩展。  
[EMNLP 2019] BookQA: Stories of Challenges and Opportunities  
[ACL 2019] Simple and Effective Curriculum Pointer-Generator Networks for Reading Comprehension over Long Narratives  
[ACL 2019] ELI5: Long Form Question Answering  
[ACL 2018] Multi-Passage Machine Reading Comprehension with Cross-Passage Answer Verification  
[ACL 2019] Token-level Dynamic Self-Attention Network for Multi-Passage Reading Comprehension  
[EMNLP 2019] Multi-passage BERT: A Globally Normalized BERT Model for Open-domain Question Answering  
[ACL 2019] Retrieve, Read, Rerank: Towards End-to-End Multi-Document Reading Comprehension  
[ACL 2019] Multi-hop reading comprehension across multiple documents by reasoning over heterogeneous graphs  
EMNLP19 - PullNet: Open Domain Question Answering with Iterative Retrieval on Knowledge Bases and Text
- QA 系统的可解释性  
比如可以将对答案的解释也作为训练数据的一部分，让模型学会解释。  
[NAACL 2019] Enhancing Key-Value Memory Neural Networks for Knowledge Based Question Answering  
[EMNLP 2017] QUINT: Interpretable Question Answering over Knowledge Bases  
[ACL 2019] Interpretable Question Answering on Knowledge Bases and Text  
[ACL 2019] Explore, Propose, and Assemble: An Interpretable Model for Multi-Hop Reading Comprehension
- 不可回答的问题这个问题  
包括无法回答的问题和合理答案的判别两个任务。  
[AAAI 2019] Read + Verify: Machine Reading Comprehension with Unanswerable Questions  
[ACL 2019] Learning to Ask Unanswerable Questions for Machine Reading Comprehension
- 数据集的构建  
更实用、智能、强大的 QA 系统需要更多优质的数据集来推动。  
[EMNLP 2019] BiPaR: A Bilingual Parallel Dataset for Multilingual and Cross-lingual Reading Comprehension on Novels 多语言与跨语言的小说阅读理解  
[EMNLP 2019] GeoSQA: A Benchmark for Scenario-based Question Answering in the Geography Domain at High School Level 高中地理场景下的问答基准测试  
[EMNLP 2019] Quoref: A Reading Comprehension Dataset with Questions Requiring Coreferential Reasoning 共指解析问题  
[IJCAI 2019] AmazonQA: A Review-Based Question Answering Task 基于评论的问答  
[EMNLP 2019] BiPaR: A Bilingual Parallel Dataset for Multilingual and Cross-lingual Reading Comprehension Novels  
- 多语言和跨语言阅读理解小说的双语并行数据集  
[ACL 2019] XQA: A Cross-lingual Open-domain Question Answering Dataset 跨语言开放域问答数据集  
[ACL 2019] WEETQA: A Social Media Focused Question Answering Dataset 社交媒体问答数据集  
[EMNLP 2019] A Span-Extraction Dataset for Chinese Machine Reading Comprehension 中文阅读跨度提取数据集


> 作者：Y.Shu
> 链接：https://www.zhihu.com/question/349499033/answer/900173774
> 来源：知乎
> 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
